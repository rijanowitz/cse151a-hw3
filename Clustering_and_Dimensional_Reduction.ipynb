{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNepbxuvBNWi"
      },
      "source": [
        "# Homework 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M5d3VPpBNWm"
      },
      "source": [
        "## Message from your Prof\n",
        "> **Remember for the best way to learn this content, and maximize your learning experience, you must implement these models yourself and only use imports for checking your work**\n",
        "\n",
        "You can only import classification_report from sklearn evaluation metrics (you do not need to implement classification report), but you have to implement the train_test_split, and the classifiers yourselves. You will need to use numpy or pandas as inputs for your models. You should only use the imports listed below to check your work.\n",
        "\n",
        "Students that do not practice their own implementations **will be cooked** in their skill assessments. I do not want to hear students complaining they did poorly because the homeworks did not reflect the skill assessments. YOU HAVE BEEN WARNED!!!\n",
        "\n",
        "<br>\n",
        "In this assignment, we are working on a list of 1200 bitstrings, where each of them contains 16 bits. <br >\n",
        "We will apply Agglomerative Clustering, K-means Clustering, and PCA to this dataset. <br >\n",
        "\n",
        "## Background and Data Information\n",
        "For a bitstring $S$ in this dataset, we describe $S = \\{s_{15}, s_{14}, s_{13}, s_{12}, \\ldots, s_{0} \\}$, where $s_{15}$ is often known as the most significant bit (MSB) and $s_0$ as the least significant bit (LSB). <br >\n",
        "\n",
        "There are duplicated bitstrings in this dataset, but they will not affect this assignment. Don't worry about them. <br >\n",
        "\n",
        "## Equivalence Relation\n",
        "\n",
        "**This is an important concept to Exercise 1.**\n",
        "\n",
        "Let's say if we have two bitstrings, $A = \\{a_{15}, a_{14}, a_{13}, \\ldots, a_{0} \\}$ and $B = \\{b_{15}, b_{14}, b_{13}, \\ldots, b_{0} \\}$. <br >\n",
        "\n",
        "We can flip one bit $a_i$ in $A$ to get another bitstring $A'$, such that the difference of $A$ and $A'$ is only one bit. We define the above transformation to be $A \\to A'$. <br >\n",
        "\n",
        "\n",
        "We call two bitstrings $A$ and $B$ to be **equivalent** ($A \\sim B$) if there exists a sequence $A \\to C_1 \\to C_2 \\to \\cdots \\to C_n \\to B$, where $\\forall i, C_i$ belongs to the dataset.\n",
        "\n",
        "It can be seen that equivalence is both __commutative__ ($A \\sim B \\iff B \\sim A$) as well as __transitive__ ($A \\sim B, B \\sim C \\implies A \\sim C$). <br >\n",
        "\n",
        "We can say that the elements in the above sequence $\\{ A, C_1, \\ldots, C_n, B\\}$ form an equivalence class. Given a new bitstring $X$, we can see that if $X \\sim C_i$, $1 \\le i \\le n$, then $X$ will be added to the above equivalence class, and by the transitive property of equivalence relations, $X \\sim A$, and $X \\sim B$.\n",
        "\n",
        "### Example\n",
        "\n",
        "Let's say we have 4 bitstrings, each of them is 4 bits long. They are $0000, 0010, 0110, 1100$, respectively.<br >\n",
        "\n",
        "We can say $0000 \\sim 0110$ because $0000 \\to 0010 \\to 0110$. <br >\n",
        "\n",
        "However, $0000 \\nsim 1100$. There may be sequences like $0000 \\to 1000 \\to 1100$ or $0000 \\to 0100 \\to 1100$, but neither $1000$ nor $0100$ is in our dataset. <br >\n",
        "\n",
        "Ultimately, $\\{0000, 0010, 0110\\}$ form an equivalence class, whereas $\\{1100\\}$ is the other. As a result, there are two classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddqEVDQwBNWo"
      },
      "source": [
        "### Libraries that can be used: numpy, scipy, pandas, scikit-learn, matplotlib, seaborn\n",
        "Any libraries used in the discussion and lecture materials are also allowed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dca6xFznXOvX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "141d0539-9ee0-4787-c5cd-32bd3c603118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'hw3' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ucsd-cse151a-ss25/hw3.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACCnVnK6BNWq"
      },
      "source": [
        "# Exercises\n",
        "## Exercise 1 - Agglomerative Clustering (20 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiKJO3a3BNWr"
      },
      "source": [
        "Using agglomerative clustering with a distance threshold for early stopping, we can calculate the number of equivalence classes by counting the number of clusters. In order to perform agglomerative clustering, we have to consider what parameters may be used: <br >\n",
        "\n",
        "### Exercise 1.1 - Choosing Parameters (5 points)\n",
        "\n",
        " - Explain why you would pick these parameters.\n",
        "     - Which linkage rule should be used? (single-linkage, complete-linkage, or average-linkage)\n",
        "     - Which distance function should be used? (Euclidean distance, Manhattan distance, or cosine distance)\n",
        "     - What should the threshold distance be?\n",
        "\n",
        "Hints:\n",
        " - How the distance threshold works: Whenever two clusters are picked to consider merging them, the distance between those clusters is compared to the distance threshold. If the distance is smaller than the threshold, the clusters merge and the algorithm continues; Otherwise, they will not be merged.\n",
        " - How to choose a linkage rule: Think about how you would figure out which equivalence class the string $0001$ belongs to in the previously given example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YbPKru-hBNWt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "db72da36-bf99-497f-e38d-daa86256e8e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      b15  b14  b13  b12  b11  b10  b9  b8  b7  b6  b5  b4  b3  b2  b1  b0\n",
              "0       0    0    0    0    0    0   1   1   0   1   1   1   1   1   0   0\n",
              "1       0    0    0    0    0    0   1   1   0   0   1   1   1   1   0   0\n",
              "2       0    0    0    0    0    0   0   1   0   0   1   1   1   1   0   0\n",
              "3       0    0    0    0    0    0   1   1   0   0   1   1   1   1   0   0\n",
              "4       0    0    0    0    0    1   1   1   0   0   1   1   1   1   0   0\n",
              "...   ...  ...  ...  ...  ...  ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
              "1195    1    1    0    1    1    1   1   1   1   0   0   0   1   1   1   1\n",
              "1196    1    1    0    1    1    1   1   1   1   0   0   0   1   1   1   0\n",
              "1197    1    1    0    1    1    1   1   1   1   1   0   0   1   1   1   1\n",
              "1198    1    1    0    1    1    1   1   1   1   1   1   1   1   1   1   1\n",
              "1199    1    0    0    1    1    1   1   1   1   1   1   0   1   1   1   1\n",
              "\n",
              "[1200 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45bb3309-b845-413d-815d-524864563e94\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>b15</th>\n",
              "      <th>b14</th>\n",
              "      <th>b13</th>\n",
              "      <th>b12</th>\n",
              "      <th>b11</th>\n",
              "      <th>b10</th>\n",
              "      <th>b9</th>\n",
              "      <th>b8</th>\n",
              "      <th>b7</th>\n",
              "      <th>b6</th>\n",
              "      <th>b5</th>\n",
              "      <th>b4</th>\n",
              "      <th>b3</th>\n",
              "      <th>b2</th>\n",
              "      <th>b1</th>\n",
              "      <th>b0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows Ã— 16 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45bb3309-b845-413d-815d-524864563e94')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-45bb3309-b845-413d-815d-524864563e94 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-45bb3309-b845-413d-815d-524864563e94');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8391e6b8-6b25-4d33-8eb3-6285a428bf9d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8391e6b8-6b25-4d33-8eb3-6285a428bf9d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8391e6b8-6b25-4d33-8eb3-6285a428bf9d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7c5f6b3f-cea4-4ea0-afd7-46a5fb31f868\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7c5f6b3f-cea4-4ea0-afd7-46a5fb31f868 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1200,\n  \"fields\": [\n    {\n      \"column\": \"b15\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b14\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b13\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b12\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b11\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"b0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('./hw3/bitstrings.csv') # change filename location based on your setup\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain why you would pick these parameters:\n",
        "\n",
        "**1. Which linkage rule should be used? (single-linkage, completely-linkage, or average-linkage)**  \n",
        "Single-linkage makes the most sense because we only care if a new bitstring is one bit away from ANY bitstring in the current cluster. The new bitstring doesn't need to be 1 bit away from all bitstrings in the cluster, and I'm unsure why taking the average would even be applicable here.\n",
        "\n",
        "**2. Which distance function should be used? (Euclidean distance, Manhattan distance, or cosine distance)**  \n",
        "Since we're concerned with the number of bits that are different in each bitstring, Manhattan distance seems to make the most sense. For instance, if we calculate the distance formulas for the bitstrings 0000 and 0110, euclidean distance gives us 1.414, cosine distance gives us a divide by zero issue, and manhattan distance gives us 2, which is the accurate \"distance\" for these bitstrings.\n",
        "\n",
        "**3. What should the threshold distance be?**  \n",
        "We want to threshold at 1 because we care about bitstrings that are 1 bit away from the cluster, not bitstrings that are more that 1 bit away from the cluster.\n",
        "\n",
        "From the previous example, single-linkage using Manhattan distance, with a threshold of 1 will give us the {0000, 0010, 0100}, {1100} equivalence classes."
      ],
      "metadata": {
        "id": "i22e2uS4xKOn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUBeJllzBNWv"
      },
      "source": [
        "### Exercise 1.2 - Agglomerative Clustering for Equivalence Classes (15 points)\n",
        "\n",
        " - Perform the agglomerative clustering with the parameters you picked in the above three questions.\n",
        " - Show the frequency(number of members) of each cluster. You are encouraged to create a bar chart to show the distribution as it will help you in Exercise 2, but printing only the numbers is also fine.\n",
        "\n",
        "Hints:\n",
        " - The value of ```distance_threshold``` in the arguments should be **slightly** higher than what you picked. This is because we only merge two clusters when their distance is **strictly smaller** than the threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yvnBbzDNBNWw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "5fad79bc-4a95-4d25-fd9e-45ca81ff6bb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hierarchical Cluster Labels: [25, 29, 29, 30, 28, 28, 25, 29, 30, 31, 28, 27, 31, 31, 31, 31, 31, 29, 31, 31, 28, 28, 30, 30, 31, 30, 26, 26, 28, 27, 31, 25, 29, 29, 29, 29, 31, 26, 25, 31, 26, 31, 26, 26, 26, 27, 31, 31, 31, 26, 30, 0, 28, 29, 28, 30, 28, 31, 30, 30, 29, 31, 30, 31, 28, 31, 25, 31, 31, 28, 28, 31, 27, 31, 31, 31, 31, 31, 30, 1, 30, 30, 27, 25, 31, 30, 30, 30, 30, 27, 30, 30, 30, 26, 26, 26, 26, 26, 26, 26, 30, 26, 26, 26, 26, 28, 28, 26, 28, 26, 28, 26, 29, 30, 30, 30, 25, 30, 30, 30, 27, 25, 25, 25, 31, 29, 29, 29, 25, 26, 25, 25, 25, 31, 29, 29, 27, 28, 28, 28, 28, 27, 28, 26, 31, 28, 28, 28, 28, 31, 28, 28, 28, 28, 28, 28, 28, 28, 28, 30, 31, 28, 29, 28, 31, 31, 31, 31, 28, 26, 31, 31, 28, 27, 28, 28, 27, 30, 30, 26, 31, 28, 28, 30, 31, 29, 29, 25, 30, 30, 2, 30, 30, 30, 27, 26, 28, 3, 31, 30, 31, 31, 31, 30, 27, 25, 27, 27, 27, 27, 27, 27, 30, 31, 31, 28, 29, 29, 26, 29, 26, 31, 29, 30, 30, 30, 30, 31, 25, 30, 27, 26, 30, 30, 29, 28, 29, 29, 29, 29, 29, 31, 30, 31, 30, 30, 30, 30, 31, 29, 31, 31, 25, 31, 30, 31, 31, 25, 29, 29, 29, 29, 25, 27, 29, 27, 28, 27, 27, 27, 4, 31, 31, 31, 31, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 29, 29, 25, 25, 30, 26, 26, 26, 26, 25, 25, 25, 25, 25, 25, 25, 25, 29, 31, 30, 30, 31, 31, 31, 25, 25, 25, 25, 30, 25, 25, 25, 25, 25, 31, 31, 31, 31, 31, 26, 31, 31, 25, 25, 25, 25, 31, 25, 31, 30, 31, 31, 30, 31, 31, 30, 5, 30, 31, 6, 30, 30, 31, 31, 31, 31, 30, 30, 30, 30, 30, 31, 31, 31, 31, 29, 7, 31, 8, 31, 31, 30, 29, 29, 25, 25, 25, 25, 25, 25, 30, 31, 9, 10, 11, 25, 31, 30, 30, 30, 30, 30, 31, 31, 31, 25, 31, 31, 29, 31, 31, 29, 29, 29, 28, 31, 27, 27, 27, 27, 28, 28, 28, 28, 27, 31, 31, 31, 30, 30, 27, 27, 28, 12, 27, 27, 27, 27, 27, 27, 27, 31, 25, 25, 31, 31, 31, 31, 31, 31, 27, 27, 27, 27, 27, 31, 31, 27, 27, 27, 27, 31, 28, 28, 28, 27, 27, 27, 27, 28, 30, 27, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 26, 26, 28, 27, 28, 28, 28, 26, 31, 28, 28, 28, 27, 28, 28, 28, 27, 28, 28, 28, 28, 31, 31, 26, 26, 26, 28, 29, 28, 25, 28, 13, 26, 31, 31, 31, 29, 31, 31, 31, 31, 31, 31, 31, 31, 28, 28, 28, 28, 28, 29, 31, 28, 26, 28, 28, 28, 27, 28, 28, 28, 28, 28, 28, 31, 31, 31, 31, 31, 31, 27, 28, 14, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 15, 31, 28, 28, 28, 27, 27, 27, 28, 29, 29, 29, 29, 29, 31, 31, 16, 31, 31, 29, 29, 28, 29, 27, 28, 17, 27, 31, 29, 31, 26, 31, 25, 26, 26, 31, 26, 26, 29, 31, 31, 31, 31, 18, 28, 28, 31, 26, 26, 26, 26, 30, 29, 30, 30, 19, 30, 30, 27, 27, 27, 20, 31, 28, 26, 26, 30, 30, 30, 30, 30, 30, 30, 30, 26, 26, 26, 26, 26, 28, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 25, 28, 25, 25, 21, 28, 28, 28, 28, 28, 25, 22, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 28, 30, 29, 29, 29, 29, 29, 29, 25, 25, 25, 29, 28, 27, 28, 25, 31, 31, 27, 30, 31, 31, 31, 31, 30, 29, 30, 29, 30, 30, 29, 29, 23, 31, 29, 29, 29, 29, 29, 29, 29, 30, 29, 29, 29, 28, 31, 30, 26, 31, 31, 31, 31, 31, 31, 31, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 29, 29, 29, 29, 29, 29, 27, 29, 29, 29, 29, 30, 27, 29, 29, 29, 29, 29, 29, 29, 31, 31, 31, 31, 31, 31, 31, 31, 29, 29, 31, 29, 29, 29, 24, 29, 29, 29, 29, 31, 27, 31, 31, 31]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Perform agglomerative clustering\n",
        "# Use single-linkage, Manhattan distance, and threshold of 1\n",
        "# The value of distance_threshold in the arguments should be slightly higher\n",
        "# than what you picked because we only merge two clusters when their distance is\n",
        "# strictly smaller than the threshold\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def manhattan_distance(p1, p2):\n",
        "    \"\"\"Calculates the Manhattan distance between two points.\"\"\"\n",
        "    return np.sum(np.abs(p1 - p2))\n",
        "\n",
        "def calculate_cluster_distance(X, cluster1, cluster2, linkage_method='single'):\n",
        "    \"\"\"\n",
        "    Calculates the distance between two clusters based on the linkage method.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    cluster1, cluster2 : list of indices\n",
        "        Lists of indices of data points belonging to each cluster.\n",
        "    linkage_method : str\n",
        "        'single', 'complete', or 'average'.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    distance : float\n",
        "        The calculated distance between the clusters.\n",
        "    \"\"\"\n",
        "    if linkage_method == 'single':\n",
        "        return min(manhattan_distance(X[i], X[j]) for i in cluster1 for j in cluster2)\n",
        "    elif linkage_method == 'complete':\n",
        "        return max(manhattan_distance(X[i], X[j]) for i in cluster1 for j in cluster2)\n",
        "    elif linkage_method == 'average':\n",
        "        return np.mean([manhattan_distance(X[i], X[j]) for i in cluster1 for j in cluster2])\n",
        "    else:\n",
        "        raise ValueError(\"Invalid linkage method\")\n",
        "\n",
        "\n",
        "def hierarchical_clustering_from_scratch(X, distance_threshold, linkage_method='single'):\n",
        "    \"\"\"\n",
        "    Agglomerative Hierarchical Clustering from scratch using NumPy.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : (n_samples, n_features) ndarray\n",
        "        The input data.\n",
        "    n_clusters : int\n",
        "        The desired number of clusters to stop at.\n",
        "    linkage_method : str\n",
        "        'single', 'complete', 'average'.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    labels : (n_samples,) ndarray\n",
        "        Cluster labels for each sample.\n",
        "    \"\"\"\n",
        "    n_samples = X.shape[0]\n",
        "    # Initially, each data point is its own cluster\n",
        "    clusters = [[i] for i in range(n_samples)]\n",
        "\n",
        "    # Merge clusters until the desired number of clusters is reached\n",
        "    while True: # Just break if outside of distance_threshold\n",
        "        min_distance = float('inf')\n",
        "        merge_indices = (-1, -1)\n",
        "\n",
        "        # Find the two closest clusters\n",
        "        for i in range(len(clusters)):\n",
        "            for j in range(i + 1, len(clusters)):\n",
        "                dist = calculate_cluster_distance(X, clusters[i], clusters[j], linkage_method)\n",
        "                if dist < min_distance:\n",
        "                    min_distance = dist\n",
        "                    merge_indices = (i, j)\n",
        "\n",
        "        if min_distance >= distance_threshold:\n",
        "            break # DO NOT MERGE IF OVER THRESHOLD\n",
        "\n",
        "        # Merge the two closest clusters\n",
        "        idx1, idx2 = merge_indices\n",
        "        merged_cluster = clusters[idx1] + clusters[idx2]\n",
        "        clusters.pop(idx2) # Remove the second cluster first to avoid index issues\n",
        "        clusters.pop(idx1)\n",
        "        clusters.append(merged_cluster)\n",
        "\n",
        "    # Assign labels based on the final clusters\n",
        "    labels = np.zeros(n_samples, dtype=int)\n",
        "    for i, cluster in enumerate(clusters):\n",
        "        for data_index in cluster:\n",
        "            labels[data_index] = i\n",
        "\n",
        "    return labels\n",
        "\n",
        "# Apply Hierarchical Clustering from scratch\n",
        "# Takes too long, count frequencies\n",
        "frequencies = df.value_counts().reset_index(name=\"frequencies\")\n",
        "# Create new array without duplicates\n",
        "nodups = frequencies.iloc[:, :-1]\n",
        "X = nodups.to_numpy(dtype=int)\n",
        "hierarchical_labels = hierarchical_clustering_from_scratch(X, distance_threshold=1.01, linkage_method='single')\n",
        "\n",
        "# Add frequencies back in\n",
        "frequencies[\"labels\"] = hierarchical_labels\n",
        "cluster_qty = frequencies.groupby(\"labels\")[\"frequencies\"].sum()\n",
        "\n",
        "# Show the frequency (# of members) of each cluster\n",
        "print(\"\\nHierarchical Cluster Labels:\", hierarchical_labels.tolist())\n",
        "\n",
        "# Create a barchart to show the distribution\n",
        "# Visualize Hierarchical Clustering results\n",
        "plt.bar(cluster_qty.index, cluster_qty.values)\n",
        "plt.xlabel('Cluster')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Agglomerative, Manhattan, Single, Threshold 1')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66TlQAHcBNWx"
      },
      "source": [
        "## Exercise 2 - K-Means Clustering (20 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMeLd_zCBNWy"
      },
      "source": [
        "Let's see how k-means behave differently from agglomerative clustering.\n",
        "\n",
        "### Exercise 2.1 - K-Means Clustering for Equivalence Classes (10 points)\n",
        " - Re-cluster the dataset with k-means, but with the number of clusters you obtained from Exercise 1.\n",
        " - Show the frequency(number of members) of each cluster. Again, you are encouraged to create a bar chart, but printing the numbers is also fine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF7fX1xnBNW0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-wcTXfIBNW1"
      },
      "source": [
        "### Exercise 2.2 - Difference between Agglomerative Clustering and K-Means Clustering (10 points)\n",
        "\n",
        "Compare the result from Exercise 2.1 with that from Exercise 1.2, and explain\n",
        " - How the two results are different\n",
        " - Why there is such a difference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubqcYkvHBNW1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ7x7XLmBNW2"
      },
      "source": [
        "## Exercise 3 - Principal Component Analysis (30 points in total)\n",
        "\n",
        "We can visualize how the bitstrings are distributed using principal component analysis.\n",
        "\n",
        "### Exercise 3.1 - Generate 2 Clusters (10 points)\n",
        "\n",
        " - Re-do the k-means clustering on our dataset again, but this time we only consider ```k=2```.\n",
        " - Show the frequency(number of members) of each cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JesfXSz2BNW2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oopLQZzNBNW3"
      },
      "source": [
        "### Exercise 3.2 - PCA for Feature Extraction (20 points)\n",
        "\n",
        " - Retrieve the projected dataset with PCA, using ```n_components=2```.\n",
        " - Generate a scatter plot to visualize the projected points, where they should be colored differently based on the assigned cluster in Exercise 3.1.\n",
        " - In the first principal component, **print out** the weights of all features.\n",
        " - Report which feature has the **highest positive** weight in the first principal component."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bBdEj7MBNW3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zub17AVhCtPj"
      },
      "source": [
        "## Exercise 4 - Singular Value Decomposition (25 points in total)\n",
        "\n",
        "Let's decompose our data set into left and right matrices to find unknown structure in our data\n",
        "\n",
        "### Exercise 4.1 - Generate the [SVD](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html) (10 points)\n",
        "\n",
        " - Generate multiple SVD's using 2, 3 and 4 components ```k=2, k=3 and k=4```.\n",
        " Give each SVD it's own python variable.\n",
        " - Calculate a pairwise cosine similarity of our kxn matrix for n features (should result in an nxn matrix)\n",
        " - Generate Pair plots for the left and right matrices.\n",
        " - Evaluate your results and what can you extract from the results of k=2, k=3 and k=4 dimensional reductions?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcIaot2GP-G4"
      },
      "source": [
        "**Before performing SVD, let's first calculate our Eigen values and Eigen vectors of our matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VgCTjBuQGdS"
      },
      "outputs": [],
      "source": [
        "eigen_values, eigen_vectors = np.linalg.eig(np.array(df).T @ np.array(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tFdAHFdQIsO"
      },
      "outputs": [],
      "source": [
        "# Let's evaluate our values. You can use this for your final evaluation for 4.1\n",
        "eigen_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzCu8XLJCv1C"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a9fR-unDbYf"
      },
      "outputs": [],
      "source": [
        "# Here we generate an SVD using k = 5 yielding u,s,v of mx5, 5x5, nx5.T\n",
        "X = df.values\n",
        "U, s, Vt = np.linalg.svd(X, full_matrices=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7nzG00ZDbi8"
      },
      "outputs": [],
      "source": [
        "k = 5\n",
        "U_k = U[:, :k]                # m Ã— 5\n",
        "s_k = s[:k]                   # length-5 vector\n",
        "Vt_k = Vt[:k, :]              # 5 Ã— n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXN_ANHkj9sf"
      },
      "outputs": [],
      "source": [
        "explained_variance = (s_k**2) / (X.shape[0] - 1)\n",
        "total_var = (s**2).sum() / (X.shape[0] - 1)\n",
        "explained_variance_ratio = explained_variance / total_var\n",
        "\n",
        "print(\"Explained variance ratio:\", explained_variance_ratio) # Prints the explained variance for each of the 5 components\n",
        "print(\"Sum of top-5 ratios:\", explained_variance_ratio.sum()) # Prints the sum of the 5 from above\n",
        "sigma_matrix = np.diag(s_k)  # Creates the sigma matrix from the singular values\n",
        "print(\"Sigma matrix:\\n\", sigma_matrix) # Prints the sigma matrix\n",
        "print(\"Singular values:\", s_k) # Our singular values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MU3qhOwCPVR0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6_yd-VMFoxU"
      },
      "outputs": [],
      "source": [
        "# We will define our cosine similarity function\n",
        "def cosine_similarity(a, b):\n",
        "    \"\"\"Calculates the cosine similarity between two vectors.\"\"\"\n",
        "    dot_product = np.dot(a, b)\n",
        "    norm_a = np.linalg.norm(a)\n",
        "    norm_b = np.linalg.norm(b)\n",
        "    return dot_product / (norm_a * norm_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LEQZPtdFamT"
      },
      "outputs": [],
      "source": [
        "right_matrix = pd.DataFrame(Vt_k)\n",
        "print(\"Right matrix shape:\", right_matrix.shape) # lets check the shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOfJ3OjdFb7_"
      },
      "outputs": [],
      "source": [
        "right_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZRjovvAKVIL"
      },
      "source": [
        "**Generate code for performing a pairwise calculation of our features using cosine_similarity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nXiav9zLRh4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prkZ-Ue7MTHh"
      },
      "source": [
        "**Let's extract our left matrix** This is similar to looking at customers with similar movie viewing habits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLFuw5xkF8Vg"
      },
      "outputs": [],
      "source": [
        "left_matrix = pd.DataFrame((U_k * s_k) / s_k)\n",
        "print(\"Left matrix shape:\", left_matrix.shape) #let's check the shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39-RT9IEF9A2"
      },
      "outputs": [],
      "source": [
        "left_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgbrvV9fRHMt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf4hhMBuJY0R"
      },
      "source": [
        "**Explain your interpretation for each of the SVD's you generated for k=2, 3, 4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWZKTM52JhTH"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohRnp0xBCvf5"
      },
      "source": [
        "### Exercise 4.2 - Generate Clusters (15 points)\n",
        "\n",
        " - Re-do the k-means clustering on our dataset again for the three different components created by you above, of the left matrix.\n",
        " - Show the frequency (number of members) of each cluster.\n",
        " - Generate clusters from 2 to 10\n",
        " - Use the [silhouette](https://scikit-learn.org/1.5/auto_examples/cluster/plot_kmeans_silhouette_analysis.html) method to choose the best k clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGHYoIckCv_G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcwzW-FoCwFZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9vFxokzBNW4"
      },
      "source": [
        "## Exercise 4 - Collaborative Statement (5 points)\n",
        "### You must fill this out even if you worked alone to get credit.\n",
        "\n",
        "It is mandatory to include a Statement of Collaboration in each submission, that follows the guidelines below.\n",
        "Include the names of everyone involved in the discussions (especially in-person ones), and what was discussed.\n",
        "All students are required to follow the academic honesty guidelines posted on the course website. For\n",
        "programming assignments in particular, I encourage students to organize (perhaps using Piazza) to discuss the\n",
        "task descriptions, requirements, possible bugs in the support code, and the relevant technical content before they\n",
        "start working on it. However, you should not discuss the specific solutions, and as a guiding principle, you are\n",
        "not allowed to take anything written or drawn away from these discussions (no photographs of the blackboard,\n",
        "written notes, referring to Piazza, etc.). Especially after you have started working on the assignment, try to restrict\n",
        "the discussion to Piazza as much as possible, so that there is no doubt as to the extent of your collaboration."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I did not discuss my code with anyone.  \n",
        "I did utilize the StatQuest video located at: https://youtu.be/7xHsRkOdVwo?feature=shared"
      ],
      "metadata": {
        "id": "3HH3rng74zXM"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}